import matplotlib
matplotlib.use('Agg')

import matplotlib.pyplot as plt
import numpy as np
import os
import seaborn as sns
import shutil

from brainpedia.brainpedia import Brainpedia
from utils.multiple_comparison import fmri_power_calculations


# ========== HYPERPARAMETERS ==========
# ***RESEARCHER BEWARE***
# Total number of GANs =
#   |NUM_SAMPLES_AVAILABLE_TO_MODEL| * NUM_MODELS_TO_TRAIN_PER_SAMPLE_SIZE * 4
NUM_SAMPLES_AVAILABLE_TO_MODEL = np.geomspace(2, 1000, num=20)
NUM_MODELS_TO_TRAIN_PER_SAMPLE_SIZE = 5
NUM_SYN_SAMPLES_TO_GENERATE = 25000
TAG = 'visual' # 'language'

DOWNSAMPLE_SCALE = 1.0
MULTI_TAG_LABEL_ENCODING = False

# ========== OUTPUT DIRECTORIES ==========
OUTPUT_DIR = 'OUTPUT/'
MODELS_OUTPUT_DIR = OUTPUT_DIR + 'MODELS/'
SYN_DATA_OUTPUT_DIR = OUTPUT_DIR + 'SYN_DATA/'
REAL_DATA_OUTPUT_DIR = OUTPUT_DIR + 'REAL_DATA/'

RESULTS_DIR = 'RESULTS/'

shutil.rmtree(OUTPUT_DIR, ignore_errors=True)
os.makedirs(MODELS_OUTPUT_DIR)
os.makedirs(SYN_DATA_OUTPUT_DIR)
os.makedirs(REAL_DATA_OUTPUT_DIR)

os.makedirs(RESULTS_DIR)


# ========== RUN PIPELINE ==========
def output_dirs(tag, n, k):
    model_tag_base = '[{0}]_[n={1}]_[k={2}]'.format(tag, n, k)
    model_1_tag = model_tag_base + '_[v=1]'
    model_2_tag = model_tag_base + '_[v=2]'

    model_1_dir = '{0}{1}/'.format(MODELS_OUTPUT_DIR, model_1_tag)
    model_2_dir = '{0}{1}/'.format(MODELS_OUTPUT_DIR, model_2_tag)

    syn_data_1_dir = '{0}{1}/'.format(SYN_DATA_OUTPUT_DIR, model_1_tag)
    syn_data_2_dir = '{0}{1}/'.format(SYN_DATA_OUTPUT_DIR, model_2_tag)

    real_data_1_dir = '{0}{1}/'.format(REAL_DATA_OUTPUT_DIR, model_1_tag)
    real_data_2_dir = '{0}{1}/'.format(REAL_DATA_OUTPUT_DIR, model_2_tag)

    return model_1_dir, model_2_dir, syn_data_1_dir, syn_data_2_dir, real_data_1_dir, real_data_2_dir


def train_and_generate_samples(num_samples_available_to_model, tag):
    for k in range(NUM_MODELS_TO_TRAIN_PER_SAMPLE_SIZE):
        # For every sample size point, for k in range(NUM_MODELS_TO_TRAIN_PER_SAMPLE_SIZE),
        # we train 4 GANs. Two GANs on data with the specified tag. Two GANs on
        # data without the specified tag. Training two GANs on each dataset
        # ensures that null tests aren't testing two synthetic samples
        # that were generated by the same GAN.

        # Set up output directories
        model_1_tag_dir, model_2_tag_dir, syn_data_1_tag_dir, syn_data_2_tag_dir, real_data_1_tag_dir, real_data_2_tag_dir = output_dirs(tag, num_samples_available_to_model, k)
        model_1_no_tag_dir, model_2_no_tag_dir, syn_data_1_no_tag_dir, syn_data_2_no_tag_dir, real_data_1_no_tag_dir, real_data_2_no_tag_dir = output_dirs('NON-' + tag, num_samples_available_to_model, k)

        # Set up paths to cache and data dirs
        tag_data_dir = 'brainpedia/data/{0}/'.format(tag)
        no_tag_data_dir = 'brainpedia/data/{0}/'.format('NON-'+tag)

        tag_cache_dir = 'brainpedia/cache/{0}/'.format(tag)
        no_tag_cache_dir = 'brainpedia/cache/{0}/'.format('NON-'+tag)

        # Set up commands to train two models on data with the tag
        train_cmd_1_tag = 'python3 train_icw_fmri_gan.py {0} {1} {2} {3}'.format(tag_data_dir, tag_cache_dir, num_samples_available_to_model, model_1_tag_dir)
        train_cmd_2_tag = 'python3 train_icw_fmri_gan.py {0} {1} {2} {3}'.format(tag_data_dir, tag_cache_dir, num_samples_available_to_model, model_2_tag_dir)

        # Set up commands to train two models on data without the tag
        train_cmd_1_no_tag = 'python3 train_icw_fmri_gan.py {0} {1} {2} {3}'.format(no_tag_data_dir, no_tag_cache_dir, num_samples_available_to_model, model_1_no_tag_dir)
        train_cmd_2_no_tag = 'python3 train_icw_fmri_gan.py {0} {1} {2} {3}'.format(no_tag_data_dir, no_tag_cache_dir, num_samples_available_to_model, model_2_no_tag_dir)

        # Set up commands to generate data from the two models trained on data with the tag
        generate_syn_cmd_1_tag = 'python3 generate_icw_fmri_gan.py {0} {1} {2} {3} {4}'.format(model_1_tag_dir + 'generator', tag_data_dir, tag_cache_dir, NUM_SYN_SAMPLES_TO_GENERATE, syn_data_1_tag_dir)
        generate_syn_cmd_2_tag = 'python3 generate_icw_fmri_gan.py {0} {1} {2} {3} {4}'.format(model_2_tag_dir + 'generator', tag_data_dir, tag_cache_dir, NUM_SYN_SAMPLES_TO_GENERATE, syn_data_2_tag_dir)

        # Set up commands to generate data from the two models trained on data without the tag
        generate_syn_cmd_1_no_tag = 'python3 generate_icw_fmri_gan.py {0} {1} {2} {3} {4}'.format(model_1_no_tag_dir + 'generator', no_tag_data_dir, no_tag_cache_dir, NUM_SYN_SAMPLES_TO_GENERATE, syn_data_1_no_tag_dir)
        generate_syn_cmd_2_no_tag = 'python3 generate_icw_fmri_gan.py {0} {1} {2} {3} {4}'.format(model_2_no_tag_dir + 'generator', no_tag_data_dir, no_tag_cache_dir, NUM_SYN_SAMPLES_TO_GENERATE, syn_data_2_no_tag_dir)

        # Set up commands to sample data from the data with the tag
        generate_real_cmd_1_tag = 'python3 sample_fmri.py {0} {1} {2}'.format(tag_data_dir, num_samples_available_to_model, real_data_1_tag_dir)
        generate_real_cmd_2_tag = 'python3 sample_fmri.py {0} {1} {2}'.format(tag_data_dir, num_samples_available_to_model, real_data_2_tag_dir)

        # Set up commands to sample data from the data without the tag
        generate_real_cmd_1_no_tag = 'python3 sample_fmri.py {0} {1} {2}'.format(no_tag_data_dir, num_samples_available_to_model, real_data_1_no_tag_dir)
        generate_real_cmd_2_no_tag = 'python3 sample_fmri.py {0} {1} {2}'.format(no_tag_data_dir, num_samples_available_to_model, real_data_2_no_tag_dir)

        # Run commands
        os.system(train_cmd_1_tag)
        os.system(train_cmd_2_tag)
        os.system(train_cmd_1_no_tag)
        os.system(train_cmd_2_no_tag)

        os.system(generate_syn_cmd_1_tag)
        os.system(generate_syn_cmd_2_tag)
        os.system(generate_syn_cmd_1_no_tag)
        os.system(generate_syn_cmd_2_no_tag)

        os.system(generate_real_cmd_1_tag)
        os.system(generate_real_cmd_2_tag)
        os.system(generate_real_cmd_1_no_tag)
        os.system(generate_real_cmd_2_no_tag)


def compute_power_between_datasets(dataset_1_dir, dataset_1_cache_dir, dataset_2_dir, dataset_2_cache_dir):
    dataset_1_brainpedia = Brainpedia(data_dirs=[dataset_1_dir],
                                      cache_dir=dataset_1_cache_dir,
                                      scale=DOWNSAMPLE_SCALE,
                                      multi_tag_label_encoding=MULTI_TAG_LABEL_ENCODING)
    dataset_2_brainpedia = Brainpedia(data_dirs=[dataset_2_dir],
                                      cache_dir=dataset_2_cache_dir,
                                      scale=DOWNSAMPLE_SCALE,
                                      multi_tag_label_encoding=MULTI_TAG_LABEL_ENCODING)
    d1, _ = dataset_1_brainpedia.all_data()
    d2, _ = dataset_2_brainpedia.all_data()

    return fmri_power_calculations(d1, d2, len(d1), len(d2), alpha=0.05, k=1)

def compute_power_tests(num_samples_available_to_model, tag):
    t_real_power_tag_null = []
    t_syn_power_tag_null = []
    t_real_power_no_tag_null = []
    t_syn_power_no_tag_null = []

    t_real_power_between_tags = []
    t_syn_power_between_tags = []

    for k in range(NUM_MODELS_TO_TRAIN_PER_SAMPLE_SIZE):
        # Retrieve data directories
        # Note syn_data_1_xxx_dir contains data generated by v=1 model.
        #      syn_data_2_xxx_dir contains data generated by v=2 model.
        # This strategy ensures that null tests aren't testing two synthetic samples
        # that were generated by the same GAN.
        _, _, syn_data_1_tag_dir, _, real_data_1_tag_dir, _ = output_dirs(tag, num_samples_available_to_model, k)
        _, _, _, syn_data_2_tag_dir, _, real_data_2_tag_dir = output_dirs(tag, num_samples_available_to_model, k)

        _, _, syn_data_1_no_tag_dir, _, real_data_1_no_tag_dir, _ = output_dirs('NON-' + tag, num_samples_available_to_model, k)
        _, _, _, syn_data_2_no_tag_dir, _, real_data_2_no_tag_dir = output_dirs('NON-' + tag, num_samples_available_to_model, k)

        # Set up paths to cache dirs
        syn_data_1_tag_cache_dir = syn_data_1_tag_dir + '___cache/'
        syn_data_2_tag_cache_dir = syn_data_2_tag_dir + '___cache/'
        real_data_1_tag_cache_dir = real_data_1_tag_dir + '___cache/'
        real_data_2_tag_cache_dir = real_data_2_tag_dir + '___cache/'
        syn_data_1_no_tag_cache_dir = syn_data_1_no_tag_dir + '___cache/'
        syn_data_2_no_tag_cache_dir = syn_data_2_no_tag_dir + '___cache/'
        real_data_1_no_tag_cache_dir = real_data_1_no_tag_dir + '___cache/'
        real_data_2_no_tag_cache_dir = real_data_2_no_tag_dir + '___cache/'

        # NULL TESTS
        # Compute power between syn_data_1_tag_dir and syn_data_2_tag_dir
        power_syn_data_1_tag_vs_syn_data_2_tag = compute_power_between_datasets(syn_data_1_tag_dir, syn_data_1_tag_cache_dir, syn_data_2_tag_dir, syn_data_2_tag_cache_dir)
        t_syn_power_tag_null.append(power_syn_data_1_tag_vs_syn_data_2_tag)

        # Compute power between real_data_1_tag_dir and real_data_2_tag_dir
        power_real_data_1_tag_vs_real_data_2_tag = compute_power_between_datasets(real_data_1_tag_dir, real_data_1_tag_cache_dir, real_data_2_tag_dir, real_data_2_tag_cache_dir)
        t_real_power_tag_null.append(power_real_data_1_tag_vs_real_data_2_tag)

        # Compute power between syn_data_1_no_tag_dir and syn_data_2_no_tag_dir
        power_syn_data_1_no_tag_vs_syn_data_2_no_tag = compute_power_between_datasets(syn_data_1_no_tag_dir, syn_data_1_no_tag_cache_dir, syn_data_2_no_tag_dir, syn_data_2_no_tag_cache_dir)
        t_syn_power_no_tag_null.append(power_syn_data_1_no_tag_vs_syn_data_2_no_tag)

        # Compute power between real_data_1_no_tag_dir and real_data_2_no_tag_dir
        power_real_data_1_no_tag_vs_real_data_2_no_tag = compute_power_between_datasets(real_data_1_no_tag_dir, real_data_1_no_tag_cache_dir, real_data_2_no_tag_dir, real_data_2_no_tag_cache_dir)
        t_real_power_no_tag_null.append(power_real_data_1_no_tag_vs_real_data_2_no_tag)

        # ALT TESTS
        # Compute power between syn_data_1_tag_dir and syn_data_2_no_tag_dir
        power_syn_data_1_tag_vs_syn_data_2_no_tag = compute_power_between_datasets(syn_data_1_tag_dir, syn_data_1_tag_cache_dir, syn_data_2_no_tag_dir, syn_data_2_no_tag_cache_dir)
        t_syn_power_between_tags.append(power_syn_data_1_tag_vs_syn_data_2_no_tag)

        # Compute power between real_data_1_tag_dir and real_data_2_no_tag_dir
        real_data_1_tag_vs_real_data_2_no_tag = compute_power_between_datasets(real_data_1_tag_dir, real_data_1_tag_cache_dir, real_data_2_no_tag_dir, real_data_2_no_tag_cache_dir)
        t_real_power_between_tags.append(real_data_1_tag_vs_real_data_2_no_tag)


    # Save power results:
    t_real_power_tag_null_for_sample_size_pth = '{0}[real]_[{1}*{2}].npy'.format(RESULTS_DIR, tag, tag)
    t_syn_power_tag_null_for_sample_size_pth = '{0}[syn]_[{1}*{2}].npy'.format(RESULTS_DIR, tag, tag)
    t_real_power_no_tag_null_for_sample_size_pth = '{0}[real]_[{1}*{2}].npy'.format(RESULTS_DIR, 'NON-'+tag, 'NON-'+tag)
    t_syn_power_no_tag_null_for_sample_size_pth = '{0}[syn]_[{1}*{2}].npy'.format(RESULTS_DIR, 'NON-'+tag, 'NON-'+tag)
    t_real_power_between_tags_for_sample_size_pth = '{0}[real]_[{1}*{2}].npy'.format(RESULTS_DIR, tag, 'NON-'+tag)
    t_syn_power_between_tags_for_sample_size_pth = '{0}[syn]_[{1}*{2}].npy'.format(RESULTS_DIR, tag, 'NON-'+tag)

    if not os.path.exists(t_real_power_tag_null_for_sample_size_pth):
        t_real_power_tag_null_for_sample_size = []
        t_syn_power_tag_null_for_sample_size = []
        t_real_power_no_tag_null_for_sample_size = []
        t_syn_power_no_tag_null_for_sample_size = []
        t_real_power_between_tags_for_sample_size = []
        t_syn_power_between_tags_for_sample_size = []
    else:
        t_real_power_tag_null_for_sample_size = np.load(t_real_power_tag_null_for_sample_size_pth).tolist()
        t_syn_power_tag_null_for_sample_size = np.load(t_syn_power_tag_null_for_sample_size_pth).tolist()
        t_real_power_no_tag_null_for_sample_size = np.load(t_real_power_no_tag_null_for_sample_size_pth).tolist()
        t_syn_power_no_tag_null_for_sample_size = np.load(t_syn_power_no_tag_null_for_sample_size_pth).tolist()
        t_real_power_between_tags_for_sample_size = np.load(t_real_power_between_tags_for_sample_size_pth).tolist()
        t_syn_power_between_tags_for_sample_size = np.load(t_syn_power_between_tags_for_sample_size_pth).tolist()

    t_real_power_tag_null_for_sample_size.append(t_real_power_tag_null)
    t_syn_power_tag_null_for_sample_size.append(t_syn_power_tag_null)
    t_real_power_no_tag_null_for_sample_size.append(t_real_power_no_tag_null)
    t_syn_power_no_tag_null_for_sample_size.append(t_syn_power_no_tag_null)
    t_real_power_between_tags_for_sample_size.append(t_real_power_between_tags)
    t_syn_power_between_tags_for_sample_size.append(t_syn_power_between_tags)

    np.save(t_real_power_tag_null_for_sample_size_pth, np.array(t_real_power_tag_null_for_sample_size))
    np.save(t_syn_power_tag_null_for_sample_size_pth, np.array(t_syn_power_tag_null_for_sample_size))
    np.save(t_real_power_no_tag_null_for_sample_size_pth, np.array(t_real_power_no_tag_null_for_sample_size))
    np.save(t_syn_power_no_tag_null_for_sample_size_pth, np.array(t_syn_power_no_tag_null_for_sample_size))
    np.save(t_real_power_between_tags_for_sample_size_pth, np.array(t_real_power_between_tags_for_sample_size))
    np.save(t_syn_power_between_tags_for_sample_size_pth, np.array(t_syn_power_between_tags_for_sample_size))


def clear_output_dirs():
    shutil.rmtree(MODELS_OUTPUT_DIR)
    shutil.rmtree(SYN_DATA_OUTPUT_DIR)
    shutil.rmtree(REAL_DATA_OUTPUT_DIR)


# ========== MAIN ==========
for i in range(NUM_SAMPLES_AVAILABLE_TO_MODEL.shape[0]):
    n = int(NUM_SAMPLES_AVAILABLE_TO_MODEL[i])
    train_and_generate_samples(n, TAG)
    compute_power_tests(n, TAG)
    clear_output_dirs()

# ========== VISUALIZATION ==========
def plot(real_data, syn_data, title, output_pth):
    plt.figure()
    sns.tsplot(data=real_data, time=NUM_SAMPLES_AVAILABLE_TO_MODEL, ci=[68, 95], color='blue', condition='T Test Real')
    sns.tsplot(data=syn_data, time=NUM_SAMPLES_AVAILABLE_TO_MODEL, ci=[68, 95], color='orange', condition='T Test Syn')
    plt.title(title)
    plt.xlabel('Real Samples')
    plt.ylabel('Power')
    plt.ylim([-0.1, 1.1])
    plt.legend(loc="upper right")
    plt.tight_layout()
    plt.savefig(output_pth)
    plt.close()

t_real_power_tag_null_for_sample_size_pth = '{0}[real]_[{1}*{2}].npy'.format(RESULTS_DIR, TAG, TAG)
t_syn_power_tag_null_for_sample_size_pth = '{0}[syn]_[{1}*{2}].npy'.format(RESULTS_DIR, TAG, TAG)
t_real_power_no_tag_null_for_sample_size_pth = '{0}[real]_[{1}*{2}].npy'.format(RESULTS_DIR, 'NON-'+TAG, 'NON-'+TAG)
t_syn_power_no_tag_null_for_sample_size_pth = '{0}[syn]_[{1}*{2}].npy'.format(RESULTS_DIR, 'NON-'+TAG, 'NON-'+TAG)
t_real_power_between_tags_for_sample_size_pth = '{0}[real]_[{1}*{2}].npy'.format(RESULTS_DIR, TAG, 'NON-'+TAG)
t_syn_power_between_tags_for_sample_size_pth = '{0}[syn]_[{1}*{2}].npy'.format(RESULTS_DIR, TAG, 'NON-'+TAG)

t_real_power_tag_null_for_sample_size = np.load(t_real_power_tag_null_for_sample_size_pth).T
t_syn_power_tag_null_for_sample_size = np.load(t_syn_power_tag_null_for_sample_size_pth).T
t_real_power_no_tag_null_for_sample_size = np.load(t_real_power_no_tag_null_for_sample_size_pth).T
t_syn_power_no_tag_null_for_sample_size = np.load(t_syn_power_no_tag_null_for_sample_size_pth).T
t_real_power_between_tags_for_sample_size = np.load(t_real_power_between_tags_for_sample_size_pth).T
t_syn_power_between_tags_for_sample_size = np.load(t_syn_power_between_tags_for_sample_size_pth).T

plot(t_real_power_tag_null_for_sample_size, t_syn_power_tag_null_for_sample_size, '{0} vs {1}'.format(TAG, TAG), '{0}[{1}*{2}].png'.format(RESULTS_DIR, TAG, TAG))
plot(t_real_power_no_tag_null_for_sample_size, t_syn_power_no_tag_null_for_sample_size, '{0} vs {1}'.format('NON-'+TAG, 'NON-'+TAG), '{0}[{1}*{2}].png'.format(RESULTS_DIR, 'NON-'+TAG, 'NON-'+TAG))
plot(t_real_power_between_tags_for_sample_size, t_syn_power_between_tags_for_sample_size, '{0} vs {1}'.format(TAG, 'NON-'+TAG), '{0}[{1}*{2}].png'.format(RESULTS_DIR, TAG, 'NON-'+TAG))
